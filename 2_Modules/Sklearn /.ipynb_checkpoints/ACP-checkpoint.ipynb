{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<hr size=\"4\" color=\"blue\">\n",
    "\n",
    "<p style=\"text-align: center;\"><span style=\"color: #0000ff;\"><font size=\"+5\"><strong> Analyse en composantes principales\n",
    "     </strong> </font></span> </p>\n",
    "<hr style=\"height: 3px; color: #0000ff; width: 50%; border: 1px dashed #000;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous présentons l’utilisation des fonctionnalités de Scikit-learn concernant l’ACP.  \n",
    "Nous rappelons que le but de cette formation est l'apprentissage de l'outil python ici pour l'analyse statistique de données et non la compréhension de la méthode...  \n",
    "\n",
    "\n",
    "Après une brève présentation de la classe correspondante de Scikit-learn, nous examinons d’abord des données générées de façon contrôlée afin de mieux comprendre l’impact de la distribution des données sur les résultats de l’ACP. Un exemple introductif au projet  basés sur des données réelles, est réalisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dans Scikit-learn, l’analyse en composantes principales (ACP) est mise en œuvre dans la classe sklearn.decomposition.PCA (voir http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). Les variantes et quelques exemples sont présentés sur http://scikit-learn.org/stable/modules/decomposition.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour définir l’analyse on appelle  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #FF3A37; padding: 3px; background-color: #FFC1C0; -moz-border-radius-topleft: 5px; -moz-border-radius-topright: 5px; -moz-border-radius-bottomright: 5px; -moz-border-radius-bottomleft: 5px;\">\n",
    "\n",
    "***PCA(n_components=None, copy=True, whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto', random_state=None).***\n",
    "   \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres d’appel sont (pour des explications plus détaillées voir le lien ci-dessus) :\n",
    "\n",
    "- **n_components**  : nombre de composantes à conserver (par défaut toutes, c’est à dire min(n_samples, n_features) où n_samples est le nombre de lignes de la matrice de données et n_features le nombre de colonnes).\n",
    "- **copy** : si False, la matrice de données est écrasée par les données transformées (par défaut True).\n",
    "- **whiten** : si True, les données transformées sont modifiées pour que les projections sur les axes principaux présentent une variance unitaire (par défaut False).\n",
    "- **svd_solver** : solveur à employer parmi 'auto', 'full', 'arpack', 'randomized' (par défaut 'auto').\n",
    "- **tol, iterated_power, random_state**: paramètres optionnels pour solveurs spécifiques.\n",
    "\n",
    "Les attributs accessibles sont les suivants :\n",
    "\n",
    "- **explained_variance_** : array [n_components] dans lequel on trouve les valeurs propres en ordre décroissant.\n",
    "- **components_** : array [n_components, n_features] dans lequel chaque ligne correspond à un vecteur propre ; l’ordre est celui des valeurs propres.\n",
    "- **explained_variance_ratio_** : array [n_components] avec les valeurs propres exprimées en pourcentage de la variance expliquée.\n",
    "- **mean_** : array [n_features] contenant les moyennes des variables calculées lors de l’ACP.\n",
    "- **n_components_** : nombre estimé de composantes.\n",
    "- **noise_variance_** : variance du bruit estimée suivant l’approche de l’ACP probabiliste (voir lien ci-dessus).  \n",
    "\n",
    "Les méthodes qui peuvent être employées :\n",
    "\n",
    "- **fit(X[, y])** : trouver les axes principaux et les valeurs propres associés à partir de la matrice de données X.\n",
    "- **fit_transform(X[, y])**: trouver les axes principaux et les valeurs propres associés, appliquer la projection sur les axes principaux (avec stockage des résultats dans la matrice de données X si copy=False et dans une autre matrice si copy=True).\n",
    "- **get_covariance()** : calculer les covariances à partir de la matrice de données.\n",
    "- **get_params([deep])** : retourner les paramètres de l’estimateur.\n",
    "- **get_precision()** : calculer la matrice de précision des données.\n",
    "- **inverse_transform(X[, y])** : re-projeter les données transformées dans l’espace initial.\n",
    "- **score(X[, y])** : valeur moyenne de la log-vraisemblance pour toutes les observations.\n",
    "- **score_samples(X)** : log-vraisemblance pour chaque observation.\n",
    "- **set_params(params)** : donner des valeurs aux paramètres de l’estimateur.\n",
    "- **atransform(X[, y])** : appliquer la projection sur les axes principaux (avec stockage des résultats dans la matrice de données X si copy=False et dans une autre matrice si copy=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  <span style=\"color: #0000ff;\"><font size=\"+2\"><strong> 1. Exemple ACP de données générées </strong> </font> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b7c74cbf5af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Démarrez par la génération d’un ensemble de 500 vecteurs dans l’espace 3D, suivant une loi normale (de moyenne nulle et de variance unitaire), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "rndn3d = np.random.randn(500,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ensuite visualisez les points générés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(rndn3d[:,0],rndn3d[:,1],rndn3d[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez ensuite l’ACP à ces données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-16642adefc05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrndn3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3,copy=True,whiten=False)\n",
    "pca.fit(rndn3d)\n",
    "pca.explained_variance_ratio_\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque ligne de <font size=\"+1\"> <span style=\"background:#E7E7E7;text-decoration: underline;\"><strong>  pca.components_ </strong></span></font>  représente le vecteur unitaire qui donne la direction d’un axe factoriel. Le vecteur pca.components_[i,:] correspond à la valeur propre pca.explained_variance_ratio_[i]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que chaque exécution les trois valeurs propres sont chaque fois très proches entre elles, ce qui indique que le nuage d’observations a une forme relativement sphérique. Ensuite, en examinant les vecteurs propres correspondants, on constate que d’un ensemble de données générées à un autre les directions des vecteurs propres changent, donc ces vecteurs n’ont pas de pertinence particulière pour décrire les données. Ce qui est cohérent avec les faibles différences entre valeurs propres successives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez maintenant une déformation et une rotation dans l’espace tridimensionnel au nuage des observations de rndn3d, visualisez le résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.array([[3,0,0],[0,1,0],[0,0,0.2]])  # matrice de déformation\n",
    "r1 = np.array([[0.36,0.48,-0.8],[-0.8,0.6,0],[0.48,0.64,0.6]])  # matrice de rotation\n",
    "rndef = rndn3d.dot(s1).dot(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(rndef[:,0],rndef[:,1],rndef[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez une ACP à ces observations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(rndef)\n",
    "PCA(copy=True, n_components=3, whiten=False)\n",
    "pca.explained_variance_ratio_\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que constatez-vous par rapport à l’application directe de l’ACP sur les données de rndn3d ? Expliquez. Peut-on lier les rapports entre les valeurs propres obtenues aux rapports entre les éléments de la diagonale de la matrice de déformation s1 ?\n",
    "\n",
    "Correction :\n",
    "On constate ici que la décroissance des valeurs propres est ici très rapide, le premier axe factoriel explique 90% de la variance. Les rapports entre valeurs propres correspondent aux carrés des rapports entre les éléments de la diagonale de la matrice de déformation. En effet, les valeurs propres sont des variances alors que les éléments de la diagonale de la matrice de déformation ont ici une signification d’écart-types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Si l'on génére un autre ensemble de données en utilisant les mêmes matrices de transformation on constate que les valeurs propres obtenues sur le second ensemble de données sont très proches de celles obtenues sur rndef. De plus, entre les deux ensembles de données, les vecteurs propres correspondant aux valeurs propres de même ordre sont très similaires. Les valeurs et vecteurs propres caractérisent les (fortes) déformations appliquées aux nuages d’observations générés et sont donc relativement stables par rapport à un changement d’échantillon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  <span style=\"color: #0000ff;\"><font size=\"+2\"><strong> 2. ACP sur des données réelles (projet) </strong> </font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color: #0000ff;\"><font size=\"+1\"><strong> 2.1 Exemple sur le sommeil de mammifère ACP sur des données réelles (projet) </strong> </font> </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "L’ACP sera d’abord appliquée aux données concernant le sommeil des mammifères. Il est d’abord nécessaire d’uploader ces données dans le répertoire de travail à partir du nuage se trouvant dans le dossier de partage du nuage.\n",
    "\n",
    "Vous pouvez examiner le contenu de ce fichier format .csv.  \n",
    "Les données doivent être ensuite lues dans Python (sans Pandas !!!!) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.654e+03, 5.712e+03, 8.350e+00, 1.800e+00, 3.300e+00, 3.860e+01,\n",
       "        6.450e+02, 3.000e+00, 5.000e+00, 3.000e+00],\n",
       "       [1.000e+00, 6.600e+00, 6.300e+00, 2.000e+00, 8.300e+00, 4.500e+00,\n",
       "        4.200e+01, 3.000e+00, 1.000e+00, 3.000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import numpy as np\n",
    "mammals = np.loadtxt('mammals.csv', delimiter=';', usecols=[1,2,3,4,5,6,7,8,9,10], skiprows=1)\n",
    "mammals[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['African elephant  ', 'African giant pouched rat', 'Arctic Fox  ',\n",
       "       'Arctic ground squirrel ', 'Asian elephant  ', 'Baboon   ',\n",
       "       'Big brown bat ', 'Brazilian tapir  ', 'Cat   ', 'Chimpanzee   ',\n",
       "       'Chinchilla   ', 'Cow   ', 'Desert hedgehog  ', 'Donkey   ',\n",
       "       'Eastern American mole ', 'Echidna   ', 'European hedgehog  ',\n",
       "       'Galago   ', 'Genet   ', 'Giant armadillo  ', 'Giraffe   ',\n",
       "       'Goat   ', 'Golden hamster  ', 'Gorilla   ', 'Gray seal  ',\n",
       "       'Gray wolf  ', 'Ground squirrel  ', 'Guinea pig  ', 'Horse   ',\n",
       "       'Jaguar   ', 'Kangaroo   ', 'Lesser short-tailed shrew ',\n",
       "       'Little brown bat ', 'Man   ', 'Mole rat  ', 'Mountain beaver  ',\n",
       "       'Mouse   ', 'Musk shrew  ', 'N. American opossum ',\n",
       "       'Nine-banded armadillo  ', 'Okapi   ', 'Owl monkey  ',\n",
       "       'Patas monkey  ', 'Phanlanger   ', 'Pig   ', 'Rabbit   ',\n",
       "       'Raccoon   ', 'Rat   ', 'Red fox  ', 'Rhesus monkey  ',\n",
       "       'Rock hyrax (Hetero. b)', 'Rock hyrax (Procavia hab)',\n",
       "       'Roe deer  ', 'Sheep   ', 'Slow loris  ', 'Star nosed mole ',\n",
       "       'Tenrec   ', 'Tree hyrax  ', 'Tree shrew  ', 'Vervet   ',\n",
       "       'Water opossum  ', 'Yellow-bellied marmot  '], dtype='<U26')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noms = np.genfromtxt('mammals.csv', dtype='str', delimiter=';', usecols=[0], skip_header=1)\n",
    "noms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquez une ACP aux données de mammals et affichez les valeurs propres. Comparez les deux premières aux valeurs vues en cours. Que constatez-vous ? Pourquoi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(mammals)from numpy \n",
    "PCA(copy=True, n_components=None, whiten=False)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "D'après les résultats, la première valeur propre obtenue explique la quasi-totalité de la variance, \n",
    "\n",
    "\n",
    "alors que dans le cours elle expliquait moins de la moitié. L’ACP directe n’est pas une ACP normée, les variances des variables « poids » (du corps, du cerveau) sont comparativement très élevées par rapport aux variances des autres variables et dominent très largement dans la définition de la direction du premier axe factoriel. Pour avoir une analyse utile il faut centrer et réduire les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez une transformation de centrage et réduction aux variables décrivant les données de mammals (regardez le centrage et la réduction des variables (« standardization ») avec scikit-learn) et conservez le résultat dans mammalsCR. Appliquez de nouveau l’ACP, de préférence en utilisant une nouvelle instance pcaCR pour conserver pca. Comment ont évolué les valeurs propres les plus grandes ? Affichez le graphique de décroissance des valeurs propres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn import preprocessing\n",
    ">>> mammalsCR = preprocessing.scale(mammals)\n",
    ">>> pcaCR = PCA()\n",
    ">>> pcaCR.fit(mammalsCR)\n",
    "PCA(copy=True, n_components=None, whiten=False)\n",
    ">>> pcaCR.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pcaCR.explained_variance_ratio_,'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plus grande valeur propre a maintenant une valeur qui correspond au pourcentage vu en cours.\n",
    "\n",
    "Nous pouvons maintenant obtenir et afficher les projections des observations sur les deux premiers axes factoriels. Rappelons que mammalsCR contient les données transformées (variables centrées et réduites) et que pcaCR est l’instance de PCA utilisée pour analyser mammalsCR ; mammalsCR et pcaCR ont été obtenues en réponse à la question ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>mNt = pcaCR.transform(mammalsCR)\n",
    ">>> mNt[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> fig = plt.figure()\n",
    ">>> ax = fig.add_subplot(111)\n",
    ">>> for i in range(len(noms)):\n",
    "        x,y = mNt[i,0],mNt[i,1]\n",
    "        ax.scatter(x,y)\n",
    "        ax.text(x,y,noms[i])\n",
    "\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Réalisez l’affichage des projections sur les 3 premiers axes principaux ; la possibilité de rotation du graphique facilite la lecture des étiquettes textuelles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> fig = plt.figure()\n",
    ">>> ax = fig.add_subplot(111, projection='3d')\n",
    ">>> for i in range(len(noms)):\n",
    "        x,y,z = mNt[i,0],mNt[i,1],mNt[i,2]\n",
    "        ax.scatter(x,y,z)\n",
    "        ax.text(x,y,z,noms[i])\n",
    "\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les résultats de l’analyse du nuage des variables ne sont pas directement disponibles. Comment pouvez-vous les obtenir ? Affichez la projection du nuage des variables sur les deux premiers axes factoriels.\n",
    "\n",
    "\n",
    "Il suffit pour cela d’utiliser les relations de transition entre les deux analyses (voir le cours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> mammalsCRTranspose = mammalsCR.transpose()\n",
    ">>> irlambdas = 1/np.sqrt(pcaCR.explained_variance_)\n",
    ">>> mirlambdas = np.diagflat(irlambdas)\n",
    ">>> projectionsVars = (mammalsCRTranspose.dot(mNt)).dot(mirlambdas)/62\n",
    ">>> nomsVars = np.genfromtxt('mammals.csv', dtype='str', delimiter=';', skip_header=0, max_rows=1)\n",
    ">>> fig = plt.subplots()\n",
    ">>> ax = fig.add_subplot(111)\n",
    ">>> ax.set_autoscalex_on(False)\n",
    ">>> ax.set_autoscaley_on(False)\n",
    ">>> ax.set_xlim([-1, 1])\n",
    ">>> ax.set_ylim([-1, 1])\n",
    ">>> cercle = plt.Circle((0, 0), 1, color='b', fill=False)\n",
    ">>> ax.add_artist(cercle)\n",
    ">>> for i in range(len(nomsVars)-1):\n",
    "        x,y = projectionsVars[i,0],projectionsVars[i,1]\n",
    "        ax.scatter(x,y)\n",
    "        ax.arrow(0, 0, x, y, shape='full', lw=1, length_includes_head=True)\n",
    "        ax.text(x,y,nomsVars[i+1])\n",
    "\n",
    ">>> plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color: #0000ff;\"><font size=\"+1\"><strong> 2.2 A toi de jouer Doris </strong> </font> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
